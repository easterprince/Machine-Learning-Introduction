{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "## Открытый курс по машинному обучению.\n",
    "<center> Автор материала: Павел Нестеров (@mephistopheies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/1dx3v1HMjVIiS9ixnXzlIm7jDb-iDYNlCHMe224w2o8E/edit?usp=sharing).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.4\n",
      "IPython 7.8.0\n",
      "\n",
      "numpy 1.16.5\n",
      "scipy 1.3.1\n",
      "pandas 0.25.1\n",
      "matplotlib 3.1.1\n",
      "sklearn 0.21.3\n",
      "\n",
      "compiler   : MSC v.1915 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 94 Stepping 3, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : 12f890fda8b7c81b0ff9ffde4ef9637115fc1c53\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html', 'javascript', 'c#', 'jquery', 'java', 'android', 'php', 'c++', 'ios', 'python'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\textbf{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} = \\sigma_k\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\textbf{x}, y}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\textbf{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\textbf{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\textbf{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\textbf{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$ <---\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$ <---\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        word_idx = self._vocab[word]\n",
    "                        z += self._w[tag][word_idx]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    exp_neg_z = np.exp(min(max(-z, -10), 10))\n",
    "                    sigma = 1 / (1 + exp_neg_z)\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    log_arg = max(tolerance, sigma if y == 1 else 1 - sigma)\n",
    "                    sample_loss += -np.log(log_arg)\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate * dLdw\n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4feaed04bd044663846ad774c2ea5a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 6.85\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(\\textbf W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
